{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3bce300-dc0d-42cf-a720-3fa0615943d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import gc\n",
    "\n",
    "DEVICE = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f35c7ea0-3f5e-49e0-bba2-760b979f11a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class AmsSketch:\n",
    "    \"\"\"\n",
    "    AMS Sketch class for approximate second moment estimation in PyTorch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, depth=3, width=500):\n",
    "        \n",
    "        self.depth = depth\n",
    "        self.width = width\n",
    "        \n",
    "        self.epsilon = 1. / sqrt(width)\n",
    "\n",
    "        self.F = torch.randint(0, (1 << 31) - 1, (6, depth), dtype=torch.int32)\n",
    "\n",
    "        # Dictionary to store precomputed results\n",
    "        self.precomputed_dict = {}\n",
    "\n",
    "    def precompute(self, d):\n",
    "        pos_tensor = self.tensor_hash31(torch.arange(d), self.F[0], self.F[1]) % self.width  # shape=(d, depth)\n",
    "        four = self.tensor_fourwise(torch.arange(d)).float()  # shape=(d, depth)\n",
    "        self.precomputed_dict[('pos_tensor', d)] = pos_tensor.to(DEVICE)  # shape=(d, depth)\n",
    "        self.precomputed_dict[('four', d)] = four.to(DEVICE)  # shape=(d, depth)\n",
    "\n",
    "    @staticmethod\n",
    "    def hash31(x, a, b):\n",
    "        r = a * x + b\n",
    "        fold = torch.bitwise_xor(r >> 31, r)\n",
    "        return fold & 2147483647\n",
    "\n",
    "    @staticmethod\n",
    "    def tensor_hash31(x, a, b):\n",
    "        \"\"\" Assumed that x is tensor shaped (d,) , i.e., a vector (for example, indices, i.e., torch.arange(d)) \"\"\"\n",
    "        x_reshaped = x.unsqueeze(-1)\n",
    "        r = a * x_reshaped + b\n",
    "        fold = torch.bitwise_xor(r >> 31, r)\n",
    "        return fold & 2147483647\n",
    "\n",
    "    def tensor_fourwise(self, x):\n",
    "        \"\"\" Assumed that x is tensor shaped (d,) , i.e., a vector (for example, indices, i.e., torch.arange(d)) \"\"\"\n",
    "        in1 = self.tensor_hash31(x, self.F[2], self.F[3])  # shape = (`x_dim`, `depth`)\n",
    "        in2 = self.tensor_hash31(x, in1, self.F[4])  # shape = (`x_dim`, `depth`)\n",
    "        in3 = self.tensor_hash31(x, in2, self.F[5])  # shape = (`x_dim`, `depth`)\n",
    "\n",
    "        in4 = in3 & 32768  # shape = (`x_dim`, `depth`)\n",
    "        return 2 * (in4 >> 15) - 1  # shape = (`x_dim`, `depth`)\n",
    "\n",
    "    def sketch_for_vector(self, v):\n",
    "        \"\"\" Efficient computation of sketch using PyTorch tensors.\n",
    "\n",
    "        Args:\n",
    "        - v (torch.Tensor): Vector to sketch. Shape=(d,).\n",
    "\n",
    "        Returns:\n",
    "        - torch.Tensor: An AMS Sketch. Shape=(`depth`, `width`).\n",
    "        \"\"\"\n",
    "        d = v.shape[0]\n",
    "\n",
    "        if ('four', d) not in self.precomputed_dict:\n",
    "            self.precompute(d)\n",
    "\n",
    "        four, pos_tensor = self.precomputed_dict[('four', d)], self.precomputed_dict[('pos_tensor', d)]\n",
    "        \n",
    "        sketch = self._sketch_for_vector(v, four, pos_tensor)\n",
    "        \n",
    "        gc.collect()\n",
    "        \n",
    "        return sketch\n",
    "\n",
    "    def _sketch_for_vector(self, v, four, pos_tensor):\n",
    "        \"\"\"\n",
    "        PyTorch translation of the TensorFlow function using a simple for loop.\n",
    "\n",
    "        Args:\n",
    "        - v (torch.Tensor): Vector to sketch. Shape=(d,).\n",
    "        - four (torch.Tensor): Precomputed fourwise tensor. Shape=(d, depth).\n",
    "        - indices (torch.Tensor): Precomputed indices for scattering. Shape=(d, depth, 2).\n",
    "\n",
    "        Returns:\n",
    "        - sketch (torch.Tensor): The AMS sketch tensor. Shape=(depth, width).\n",
    "        \"\"\"\n",
    "\n",
    "        # Expand the input vector v to match dimensions for element-wise multiplication\n",
    "        v_expand = v.unsqueeze(-1).to(DEVICE)  # shape=(d, 1)\n",
    "\n",
    "        # Element-wise multiply v_expand and four to get deltas\n",
    "        deltas_tensor = four * v_expand  # shape=(d, depth)\n",
    "\n",
    "        # Initialize the sketch tensor with zeros\n",
    "        sketch = torch.zeros((self.depth, self.width), dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "        # Loop over each depth and scatter the corresponding values\n",
    "        for i in range(self.depth):\n",
    "            # Compute the width indices on the fly\n",
    "            width_indices = pos_tensor[:, i]  # shape=(d,), indices for the width dimension\n",
    "            \n",
    "            deltas = deltas_tensor[:, i]\n",
    "\n",
    "            # Add the deltas_tensor[:, i] (shape=(d,)) into the correct rows\n",
    "            # using index_add on the width dimension\n",
    "            sketch[i].index_add_(0, width_indices, deltas)\n",
    "\n",
    "        return sketch\n",
    "\n",
    "    @staticmethod\n",
    "    def estimate_euc_norm_squared(sketch):\n",
    "        \"\"\" Estimate the Euclidean norm squared of a vector using its AMS sketch.\n",
    "\n",
    "        Args:\n",
    "        - sketch (torch.Tensor): AMS sketch of a vector. Shape=(`depth`, `width`).\n",
    "\n",
    "        Returns:\n",
    "        - float: Estimated squared Euclidean norm.\n",
    "        \"\"\"\n",
    "        norm_sq_rows = torch.sum(sketch ** 2, dim=1)\n",
    "        return torch.median(norm_sq_rows).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdd751f-79fa-4ea9-877a-8bd29f8d7272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e165e719-ee0e-4e47-a3f6-938642ba5ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c1a87a-75cb-4968-9b04-184b1053dca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0387dd7f-4c86-4e81-a907-be702d90d4ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ams_sketch = AmsSketch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc73e283-7822-4245-b2d8-ef02fb20af06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1077708736,  775553956,  197980044],\n",
       "        [1378570210,  759419985,  667263297],\n",
       "        [ 186700019,  431933018,  500035991],\n",
       "        [1822604758,  446099739, 1236368238],\n",
       "        [ 820040940, 1133144505,  723769476],\n",
       "        [ 871766692, 1792924851, 1434257607]], dtype=torch.int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ams_sketch.F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a93c8162-9b0e-4c4b-ac1e-576ec23b2743",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1608637542, 1273642420, 1935803229],\n",
       "        [ 787846414,  996406379, 1201263688],\n",
       "        [ 423734973,  415968277,  670094950],\n",
       "        [1914837113,  669991378,  429389014],\n",
       "        [ 249467210, 1972458954, 1572714584],\n",
       "        [1433267572,  434285668,  613608295]], dtype=torch.int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ams_sketch.F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b1c384-33b7-4be3-894a-b831306519da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "017c4350-6e59-46c5-80b9-530ff56b3094",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0670)\n",
      "tensor(0.0705)\n",
      "tensor(0.0449)\n",
      "tensor(0.0664)\n",
      "tensor(0.0067)\n",
      "tensor(0.1256)\n",
      "tensor(0.0938)\n",
      "tensor(0.0893)\n",
      "tensor(0.0602)\n",
      "tensor(0.0464)\n",
      "tensor(0.0781)\n",
      "tensor(0.0488)\n",
      "tensor(0.0454)\n",
      "tensor(0.0262)\n",
      "tensor(0.0615)\n",
      "tensor(0.1158)\n",
      "tensor(0.1045)\n",
      "tensor(0.0785)\n",
      "tensor(0.0740)\n",
      "tensor(0.0133)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    v1 = torch.rand(100_000_000)\n",
    "    sk1 = ams_sketch.sketch_for_vector(v1)\n",
    "    est = ams_sketch.estimate_euc_norm_squared(sk1)\n",
    "    print(abs(est - torch.dot(v1,v1)) / est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a78a7-b6a8-4226-982b-4dd249289b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1a7fda-8714-4268-9af8-bf47e04420b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c477dc9-6fec-4c55-b7c5-7e03cc5ab356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf7b7509-14eb-4ab1-8e27-5a8964f1b6c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "v1 = torch.rand(1000)\n",
    "v2 = torch.rand(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61211902-fcc7-4b8d-9192-05dc4e9af4ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sk1 = ams_sketch.sketch_for_vector(v1)\n",
    "sk2 = ams_sketch.sketch_for_vector(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c847fa7d-fc47-4959-82f1-5b58dd9e5f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "413b9911-beb0-4b67-8e1f-85f8b9a543ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368.45062255859375"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ams_sketch.estimate_euc_norm_squared(sk1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb483f89-4f4c-4f94-82b2-0b86ffe03a65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(357.6067)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(v1,v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47beb672-7a7a-4df1-9bd7-18fee0157e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c43f02e-b1ce-441e-a719-2ab222c56376",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334.3333740234375"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ams_sketch.estimate_euc_norm_squared(sk2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fd7f4f1-6223-4265-b40c-da249365724e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(332.4880)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.dot(v2,v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafacb85-06ca-4ad5-9a85-69c2f9f8a987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9851a77e-d529-4827-8e29-825b4a1a4bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sk_l = ams_sketch.sketch_for_vector(v1+v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54366199-3e5d-4480-aa96-0b551288ee89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7485,  0.3308, -0.9262,  ...,  2.5623, -1.4802, -0.2253],\n",
       "        [-0.7550, -0.5428,  2.0598,  ...,  1.9245,  0.5743,  1.6090],\n",
       "        [-4.0223,  0.0695,  1.3860,  ...,  0.4399,  1.7191,  2.7875],\n",
       "        [-1.6184,  2.8533, -1.1031,  ...,  5.1887,  2.1836,  5.7894],\n",
       "        [-5.6956, -1.1338, -6.5732,  ..., -1.7909, -0.3551, -3.2422]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk1+sk2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dc7d8e2-a347-4e76-aea5-57858172205c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7485,  0.3308, -0.9262,  ...,  2.5623, -1.4802, -0.2253],\n",
       "        [-0.7550, -0.5428,  2.0598,  ...,  1.9245,  0.5743,  1.6090],\n",
       "        [-4.0223,  0.0695,  1.3860,  ...,  0.4399,  1.7191,  2.7875],\n",
       "        [-1.6184,  2.8533, -1.1031,  ...,  5.1887,  2.1836,  5.7894],\n",
       "        [-5.6956, -1.1338, -6.5732,  ..., -1.7909, -0.3551, -3.2422]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69059ef-0341-4fdf-9ac2-7833e48bbd03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6f8469-0355-4057-a972-4793df0330cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
